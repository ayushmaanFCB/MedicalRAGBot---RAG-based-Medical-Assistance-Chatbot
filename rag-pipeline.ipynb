{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CSE 453 - Tensorflow and other tools in Healthcare\\Medical Chatbot Deployment\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\CSE 453 - Tensorflow and other tools in Healthcare\\Medical Chatbot Deployment\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from components.response import retrieve_context, generate_response, embed_question\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"original_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/embeddings/corpus.json\", \"r\") as f:\n",
    "    corpus = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question, retrieved_context):\n",
    "    # Prepare the input\n",
    "    input_text = f\"Context: {retrieved_context} Question: {question}\"\n",
    "\n",
    "    # Tokenize the input text\n",
    "    encoding = tokenizer(\n",
    "        input_text, return_tensors=\"tf\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "\n",
    "    # Convert to lists for JSON serialization\n",
    "    input_ids = encoding[\"input_ids\"].numpy().tolist()\n",
    "    attention_mask = encoding[\"attention_mask\"].numpy().tolist()\n",
    "\n",
    "    # For T5, decoder_input_ids can be the same as input_ids for inference\n",
    "    decoder_input_ids = input_ids  # This is typically the same for inference\n",
    "    decoder_attention_mask = attention_mask  # This is typically the same for inference\n",
    "\n",
    "    # Prepare the payload for TensorFlow Serving\n",
    "    payload = {\n",
    "        \"signature_name\": \"serving_default\",\n",
    "        \"instances\": [\n",
    "            {\n",
    "                \"input_ids\": input_ids[0],  # Use the first (and only) input\n",
    "                \"attention_mask\": attention_mask[0],  # Include attention mask\n",
    "                \"decoder_input_ids\": decoder_input_ids[0],  # Include decoder input ids\n",
    "                \"decoder_attention_mask\": decoder_attention_mask[\n",
    "                    0\n",
    "                ],  # Include decoder attention mask\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Send the request to TensorFlow Serving\n",
    "    url = \"http://localhost:8501/v1/models/fine_tuned_t5:predict\"\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    # Check for response errors\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
    "        )\n",
    "\n",
    "    # Get the output from the response\n",
    "    output = response.json()\n",
    "\n",
    "    # Print all keys in the output\n",
    "    print(\"Response Keys:\", output.keys())  # Print the keys in the response\n",
    "\n",
    "    # Extract the predictions\n",
    "    if \"predictions\" in output:\n",
    "        predictions = output[\"predictions\"]\n",
    "        print(\"Predictions Keys:\")\n",
    "\n",
    "        # Iterate over each prediction and print its keys\n",
    "        for i, prediction in enumerate(predictions):\n",
    "            print(f\"Keys in prediction {i}:\", prediction.keys())\n",
    "\n",
    "        # Assuming we want to decode the first prediction\n",
    "        if predictions:\n",
    "            first_prediction = predictions[0]\n",
    "\n",
    "            # Check if 'logits' is present\n",
    "            if \"logits\" in first_prediction:\n",
    "                logits = first_prediction[\"logits\"]\n",
    "\n",
    "                # Get the top-k predicted token IDs for each position\n",
    "                top_k = 5  # Change this to the number of responses you want\n",
    "                top_k_indices = np.argsort(logits, axis=-1)[\n",
    "                    :, -top_k:\n",
    "                ]  # Get the indices of the top-k logits\n",
    "\n",
    "                # Decode the top-k predicted token IDs into text\n",
    "                all_responses = []\n",
    "                for k in range(top_k):\n",
    "                    predicted_ids = top_k_indices[:, k]  # Get the k-th top prediction\n",
    "                    response_text = tokenizer.decode(\n",
    "                        predicted_ids[0], skip_special_tokens=True\n",
    "                    )\n",
    "                    all_responses.append(response_text)\n",
    "\n",
    "                # Print all generated responses\n",
    "                print(\"Generated Responses:\")\n",
    "                for idx, response in enumerate(all_responses):\n",
    "                    print(f\"Response {idx + 1}: {response}\")\n",
    "            else:\n",
    "                raise ValueError(\"Expected 'logits' key not found in predictions.\")\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected output format: 'predictions' key not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(question, corpus, k=3):\n",
    "    # ncode the question\n",
    "    question_embedding = embed_question(question, retriever_model).astype(\"float32\")\n",
    "\n",
    "    # Retrieve top-k contexts\n",
    "    indices, distances = retrieve_context(question_embedding=question_embedding, k=k)\n",
    "    retrieved_context = \" \".join([corpus[i] for i in indices[0]])\n",
    "\n",
    "    print(f\"Retrieved Context: {retrieved_context}\")\n",
    "\n",
    "    generate_response(question=question, retrieved_context=retrieved_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [[0.5678699 0.5689838 0.5742972]]\n",
      "Indices: [[100444  92174  66184]]\n",
      "Retrieved Context: Hello.. I feel lower abdominal pain after eating, not always though.  Bowel movement is normal, no fever, I feel some gas in stomach and abdominal pain/ stomach burning when lying down on my stomach.  Felt nausea a couple of days but it went away.  If I touch my belly hard it huryts (slightly to the right, not lower side as towards the appendix nor upper right as towards the gallbladder).  Dr prescribed dexlansoprazole which seems to work but still hurts.. Three weeks ago I had upper stomach pain and nausea . Went to the clinic and they said I had a stomach. For the last three weeks, I have still had irritating stomach pain more after eating, nausea and green diarrhea . Also bad upper stomach rumbling and gas. I have bad acid reflux and had my gallbladder Removed 8 years ago after the birth of my son. It almost feels like the attacks I had when I had my gallbladder. Ive been having stomach pains lately but i dont have any other symptoms. It mostly husts on the lower parts. Sometimes it will hurt so bad that i have to lay down but sometimes its not that bad. I dont really like going to the doctor because it hurts really ba when they push down. any advice?\n",
      "Response Keys: dict_keys(['predictions'])\n",
      "Predictions Keys:\n",
      "Keys in prediction 0: dict_keys(['past_key_values_6_2', 'past_key_values_3_3', 'past_key_values_5_3', 'past_key_values_1_4', 'past_key_values_6_4', 'logits', 'past_key_values_2_3', 'past_key_values_3_1', 'past_key_values_2_2', 'encoder_last_hidden_state', 'past_key_values_5_1', 'past_key_values_4_3', 'past_key_values_1_2', 'past_key_values_1_3', 'past_key_values_4_2', 'past_key_values_3_2', 'past_key_values_2_4', 'past_key_values_5_4', 'past_key_values_6_3', 'past_key_values_3_4', 'past_key_values_4_1', 'past_key_values_5_2', 'past_key_values_2_1', 'past_key_values_1_1', 'past_key_values_4_4', 'past_key_values_6_1'])\n",
      "Generated Responses:\n",
      "Response 1: ,\n",
      "Response 2: .\n",
      "Response 3: Inc\n",
      "Response 4: \n",
      "Response 5: Con\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    question = \"Stomach Issue Symptoms?\"\n",
    "\n",
    "    rag_pipeline(question=question, corpus=corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
